# ==============================================
# AgentHub Database Configuration
# ==============================================

# ------------------- BIGQUERY CORE SETTINGS -------------------
# Required: Your Google Cloud Project ID
# Get this from: https://console.cloud.google.com
GOOGLE_CLOUD_PROJECT_ID=your-project-id

# Optional: BigQuery dataset name (default: agenthub)
BIGQUERY_DATASET=agenthub

# Optional: BigQuery location/region (default: US)
# Options: US, EU, asia-northeast1, etc.
BIGQUERY_LOCATION=US

# Optional: Path to Google Cloud service account key file
# If not provided, uses Application Default Credentials
GOOGLE_CLOUD_KEY_FILE=path/to/service-account-key.json

# ------------------- TABLE CONFIGURATION -------------------
# Optional: Custom table names for different environments
AGENTS_TABLE_NAME=agents
CONVERSATIONS_TABLE_NAME=conversations

# ------------------- CONNECTION SETTINGS -------------------
# Optional: Query timeout in milliseconds (default: 30000)
BIGQUERY_TIMEOUT=30000

# Optional: Number of retries for failed queries (default: 3)
BIGQUERY_RETRIES=3

# ------------------- DEVELOPMENT SETTINGS -------------------
# Optional: Enable sample data insertion (default: true)
# Set to 'false' to skip sample data in production
ENABLE_SAMPLE_DATA=true

# Optional: Log all BigQuery queries for debugging (default: false)
# Set to 'true' for development debugging
LOG_BIGQUERY_QUERIES=false

# ==============================================
# LLM PROVIDERS CONFIGURATION
# ==============================================

# ------------------- GOOGLE CLOUD / VERTEX AI -------------------
# Required for Gemini models and Google embeddings
VERTEX_AI_LOCATION=us-central1
VERTEX_AI_TIMEOUT=60
VERTEX_AI_MAX_RETRIES=3
VERTEX_AI_RETRY_DELAY=2

# ------------------- OPENAI -------------------
# Required for GPT models
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_ORGANIZATION_ID=org-your-organization-id
OPENAI_TIMEOUT=60
OPENAI_MAX_RETRIES=3
OPENAI_RETRY_DELAY=1

# ------------------- ANTHROPIC CLAUDE -------------------
# Required for Claude models
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_TIMEOUT=60
ANTHROPIC_MAX_RETRIES=3
ANTHROPIC_RETRY_DELAY=1

# ------------------- AZURE OPENAI (Optional) -------------------
# Optional: For Azure-hosted OpenAI models
AZURE_OPENAI_API_KEY=your-azure-openai-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-01
AZURE_GPT4_DEPLOYMENT_NAME=gpt-4

# ------------------- LLM FEATURES -------------------
# Debug and monitoring settings
LLM_DEBUG_LOGGING=false
LLM_DETAILED_LOGGING=false
LLM_SANDBOX_MODE=false

# Rate limiting
LLM_RATE_LIMIT_ENABLED=true
LLM_MAX_REQUESTS_PER_MINUTE=1000
LLM_MAX_TOKENS_PER_MINUTE=150000

# ==============================================
# ENVIRONMENT EXAMPLES
# ==============================================

# --- Development Environment ---
# GOOGLE_CLOUD_PROJECT_ID=my-dev-project
# BIGQUERY_DATASET=agenthub_dev
# ENABLE_SAMPLE_DATA=true
# LOG_BIGQUERY_QUERIES=true

# --- Staging Environment ---
# GOOGLE_CLOUD_PROJECT_ID=my-staging-project
# BIGQUERY_DATASET=agenthub_staging
# AGENTS_TABLE_NAME=agents_staging
# CONVERSATIONS_TABLE_NAME=conversations_staging
# ENABLE_SAMPLE_DATA=false

# --- Production Environment ---
# GOOGLE_CLOUD_PROJECT_ID=my-production-project
# BIGQUERY_DATASET=agenthub_prod
# BIGQUERY_LOCATION=US
# ENABLE_SAMPLE_DATA=false
# LOG_BIGQUERY_QUERIES=false