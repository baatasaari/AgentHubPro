#!/usr/bin/env python3
"""
Comprehensive Microservices Simulation Testing
Tests the complete platform functionality in simulated microservices mode
"""

import requests
import time
import json
import concurrent.futures
from typing import Dict, List, Any

BASE_URL = "http://localhost:5000"

class MicroservicesSimulationTester:
    def __init__(self):
        self.results = {}
        
    def test_platform_health(self) -> Dict[str, Any]:
        """Test overall platform health"""
        try:
            response = requests.get(f"{BASE_URL}/health", timeout=10)
            if response.status_code == 200:
                health_data = response.json()
                return {
                    "success": True,
                    "status": health_data.get("status"),
                    "mode": health_data.get("mode"),
                    "services": health_data.get("services"),
                    "response_time": response.elapsed.total_seconds()
                }
            else:
                return {"success": False, "status_code": response.status_code}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def test_frontend_integration(self) -> Dict[str, Any]:
        """Test frontend serving and React app"""
        try:
            response = requests.get(BASE_URL, timeout=10)
            content = response.text
            
            return {
                "success": response.status_code == 200,
                "status_code": response.status_code,
                "has_react_root": 'id="root"' in content,
                "has_vite_client": "vite" in content.lower() or "type=\"module\"" in content,
                "content_size": len(content),
                "response_time": response.elapsed.total_seconds()
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def test_agent_management_microservice(self) -> Dict[str, Any]:
        """Test agent management functionality"""
        results = {}
        
        # Test agent listing
        try:
            list_response = requests.get(f"{BASE_URL}/api/agents", timeout=10)
            results["list_agents"] = {
                "success": list_response.status_code == 200,
                "status_code": list_response.status_code,
                "agent_count": len(list_response.json()) if list_response.status_code == 200 else 0,
                "response_time": list_response.elapsed.total_seconds()
            }
        except Exception as e:
            results["list_agents"] = {"success": False, "error": str(e)}
        
        # Test agent creation
        try:
            create_data = {
                "businessName": "Test Microservice Agent",
                "businessDescription": "Testing microservices simulation",
                "businessDomain": "test-simulation.com",
                "industry": "technology",
                "llmModel": "gpt-4",
                "interfaceType": "webchat"
            }
            create_response = requests.post(f"{BASE_URL}/api/agents", json=create_data, timeout=10)
            results["create_agent"] = {
                "success": create_response.status_code == 201,
                "status_code": create_response.status_code,
                "response_time": create_response.elapsed.total_seconds()
            }
            
            if create_response.status_code == 201:
                agent_data = create_response.json()
                results["create_agent"]["agent_id"] = agent_data.get("id")
                results["create_agent"]["has_timestamp"] = "createdAt" in agent_data
        except Exception as e:
            results["create_agent"] = {"success": False, "error": str(e)}
        
        return results
    
    def test_rag_microservice(self) -> Dict[str, Any]:
        """Test RAG system functionality"""
        test_queries = [
            {"query": "What are your healthcare services?", "industry": "healthcare"},
            {"query": "How can I schedule an appointment?", "industry": "healthcare"},
            {"query": "What are your business hours?", "industry": "retail"},
            {"query": "Do you offer consultations?", "industry": "consulting"}
        ]
        
        results = []
        for test_query in test_queries:
            try:
                query_data = {
                    "query": test_query["query"],
                    "agentId": f"test_agent_{test_query['industry']}",
                    "industry": test_query["industry"],
                    "maxChunks": 5
                }
                
                start_time = time.time()
                response = requests.post(f"{BASE_URL}/api/rag/query", json=query_data, timeout=10)
                query_time = time.time() - start_time
                
                if response.status_code == 200:
                    rag_data = response.json()
                    results.append({
                        "query": test_query["query"],
                        "success": True,
                        "has_response": "response" in rag_data,
                        "has_sources": "sources" in rag_data,
                        "response_time": query_time
                    })
                else:
                    results.append({
                        "query": test_query["query"],
                        "success": False,
                        "status_code": response.status_code
                    })
            except Exception as e:
                results.append({
                    "query": test_query["query"],
                    "success": False,
                    "error": str(e)
                })
        
        successful_queries = sum(1 for r in results if r["success"])
        avg_response_time = sum(r.get("response_time", 0) for r in results if r["success"]) / max(successful_queries, 1)
        
        return {
            "successful_queries": successful_queries,
            "total_queries": len(test_queries),
            "success_rate": successful_queries / len(test_queries),
            "avg_response_time": avg_response_time,
            "query_results": results
        }
    
    def test_usage_analytics_microservice(self) -> Dict[str, Any]:
        """Test usage analytics functionality"""
        try:
            response = requests.get(f"{BASE_URL}/api/usage/stats", timeout=10)
            
            if response.status_code == 200:
                stats_data = response.json()
                required_fields = ["totalConversations", "totalCost", "activeAgents"]
                has_required = all(field in stats_data for field in required_fields)
                
                return {
                    "success": True,
                    "has_required_fields": has_required,
                    "total_conversations": stats_data.get("totalConversations", 0),
                    "active_agents": stats_data.get("activeAgents", 0),
                    "response_time": response.elapsed.total_seconds()
                }
            else:
                return {"success": False, "status_code": response.status_code}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def test_concurrent_load(self) -> Dict[str, Any]:
        """Test concurrent request handling"""
        def make_request(endpoint):
            try:
                start_time = time.time()
                response = requests.get(f"{BASE_URL}{endpoint}", timeout=10)
                return {
                    "success": response.status_code == 200,
                    "endpoint": endpoint,
                    "response_time": time.time() - start_time,
                    "status_code": response.status_code
                }
            except Exception as e:
                return {"success": False, "endpoint": endpoint, "error": str(e)}
        
        # Test endpoints concurrently
        endpoints = ["/api/agents", "/api/usage/stats", "/health"] * 5  # 15 total requests
        
        start_time = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(make_request, endpoint) for endpoint in endpoints]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        total_time = time.time() - start_time
        successful_requests = sum(1 for r in results if r["success"])
        
        return {
            "success": successful_requests >= len(endpoints) * 0.8,  # 80% success rate
            "successful_requests": successful_requests,
            "total_requests": len(endpoints),
            "total_time": total_time,
            "requests_per_second": len(endpoints) / total_time,
            "avg_response_time": sum(r.get("response_time", 0) for r in results) / len(results)
        }
    
    def test_microservices_architecture_compliance(self) -> Dict[str, Any]:
        """Test microservices architecture compliance"""
        # Test service isolation simulation
        service_endpoints = [
            "/api/agents",
            "/api/usage/stats",
            "/api/rag/query",
            "/api/conversations",
            "/api/widgets"
        ]
        
        service_tests = []
        for endpoint in service_endpoints:
            try:
                if endpoint == "/api/rag/query":
                    response = requests.post(f"{BASE_URL}{endpoint}", 
                                           json={"query": "test", "agentId": "test"}, 
                                           timeout=5)
                else:
                    response = requests.get(f"{BASE_URL}{endpoint}", timeout=5)
                
                service_tests.append({
                    "endpoint": endpoint,
                    "success": response.status_code in [200, 201],
                    "independent": True,  # Simulated - each endpoint works independently
                    "response_time": response.elapsed.total_seconds()
                })
            except Exception as e:
                service_tests.append({
                    "endpoint": endpoint,
                    "success": False,
                    "error": str(e)
                })
        
        successful_services = sum(1 for s in service_tests if s["success"])
        
        return {
            "service_isolation": successful_services >= len(service_endpoints) * 0.8,
            "successful_services": successful_services,
            "total_services": len(service_endpoints),
            "architecture_compliance": True,  # Simulated microservices architecture
            "service_details": service_tests
        }
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """Run complete microservices simulation testing"""
        print("ðŸ§ª COMPREHENSIVE MICROSERVICES SIMULATION TESTING")
        print("=" * 70)
        print()
        
        # Test 1: Platform Health
        print("1. Testing Platform Health...")
        health_result = self.test_platform_health()
        self.results["platform_health"] = health_result
        
        if health_result["success"]:
            print(f"   âœ… Platform healthy - Mode: {health_result.get('mode')}")
            print(f"   ðŸ“Š Services: {health_result.get('services')}")
        else:
            print(f"   âŒ Platform health check failed")
        print()
        
        # Test 2: Frontend Integration
        print("2. Testing Frontend Integration...")
        frontend_result = self.test_frontend_integration()
        self.results["frontend_integration"] = frontend_result
        
        if frontend_result["success"]:
            print(f"   âœ… Frontend serving successfully")
            print(f"   ðŸ“± React app: {'âœ…' if frontend_result.get('has_react_root') else 'âŒ'}")
        else:
            print(f"   âŒ Frontend integration failed")
        print()
        
        # Test 3: Agent Management Microservice
        print("3. Testing Agent Management Microservice...")
        agent_result = self.test_agent_management_microservice()
        self.results["agent_management"] = agent_result
        
        list_success = agent_result.get("list_agents", {}).get("success", False)
        create_success = agent_result.get("create_agent", {}).get("success", False)
        print(f"   âœ… Agent listing: {'âœ…' if list_success else 'âŒ'}")
        print(f"   âœ… Agent creation: {'âœ…' if create_success else 'âŒ'}")
        print()
        
        # Test 4: RAG Microservice
        print("4. Testing RAG Microservice...")
        rag_result = self.test_rag_microservice()
        self.results["rag_system"] = rag_result
        
        print(f"   âœ… Query success rate: {rag_result['success_rate']:.1%}")
        print(f"   âš¡ Avg response time: {rag_result['avg_response_time']:.3f}s")
        print()
        
        # Test 5: Usage Analytics Microservice
        print("5. Testing Usage Analytics Microservice...")
        analytics_result = self.test_usage_analytics_microservice()
        self.results["usage_analytics"] = analytics_result
        
        if analytics_result["success"]:
            print(f"   âœ… Analytics data available")
            print(f"   ðŸ“Š Conversations: {analytics_result.get('total_conversations')}")
            print(f"   ðŸ¤– Active agents: {analytics_result.get('active_agents')}")
        else:
            print(f"   âŒ Analytics service failed")
        print()
        
        # Test 6: Concurrent Load Testing
        print("6. Testing Concurrent Load Handling...")
        load_result = self.test_concurrent_load()
        self.results["concurrent_load"] = load_result
        
        if load_result["success"]:
            print(f"   âœ… Load test passed")
            print(f"   ðŸ“ˆ Requests/second: {load_result['requests_per_second']:.1f}")
        else:
            print(f"   âŒ Load test failed")
        print()
        
        # Test 7: Microservices Architecture Compliance
        print("7. Testing Microservices Architecture Compliance...")
        arch_result = self.test_microservices_architecture_compliance()
        self.results["architecture_compliance"] = arch_result
        
        if arch_result["service_isolation"]:
            print(f"   âœ… Service isolation verified")
            print(f"   ðŸ—ï¸ Architecture compliance: âœ…")
        else:
            print(f"   âŒ Service isolation issues")
        print()
        
        # Calculate overall success
        successful_tests = sum(1 for test in [
            health_result["success"],
            frontend_result["success"], 
            list_success and create_success,
            rag_result["success_rate"] >= 0.8,
            analytics_result["success"],
            load_result["success"],
            arch_result["service_isolation"]
        ] if test)
        
        total_tests = 7
        success_rate = successful_tests / total_tests
        
        # Summary
        print("=" * 70)
        print("ðŸŽ¯ MICROSERVICES SIMULATION TEST SUMMARY")
        print("=" * 70)
        print(f"Overall Success: {'âœ… EXCELLENT' if success_rate >= 0.85 else 'âš ï¸ GOOD' if success_rate >= 0.7 else 'âŒ NEEDS WORK'}")
        print(f"Success Rate: {success_rate:.1%} ({successful_tests}/{total_tests})")
        print()
        print("ðŸ“Š Test Results:")
        print(f"   Platform Health: {'âœ…' if health_result['success'] else 'âŒ'}")
        print(f"   Frontend Integration: {'âœ…' if frontend_result['success'] else 'âŒ'}")
        print(f"   Agent Management: {'âœ…' if list_success and create_success else 'âŒ'}")
        print(f"   RAG System: {'âœ…' if rag_result['success_rate'] >= 0.8 else 'âŒ'}")
        print(f"   Usage Analytics: {'âœ…' if analytics_result['success'] else 'âŒ'}")
        print(f"   Concurrent Load: {'âœ…' if load_result['success'] else 'âŒ'}")
        print(f"   Architecture Compliance: {'âœ…' if arch_result['service_isolation'] else 'âŒ'}")
        print()
        
        if success_rate >= 0.8:
            print("ðŸš€ MICROSERVICES ARCHITECTURE VALIDATION SUCCESSFUL!")
            print("   â€¢ All core microservices operational")
            print("   â€¢ Service isolation confirmed")
            print("   â€¢ Frontend integration working")
            print("   â€¢ Performance meets requirements")
            print("   â€¢ Ready for production deployment")
        else:
            print("âš ï¸  Some areas need attention:")
            print("   â€¢ Check failed test details above")
            print("   â€¢ Verify service configurations")
            print("   â€¢ Review error logs")
        
        return {
            "overall_success": success_rate >= 0.8,
            "success_rate": success_rate,
            "successful_tests": successful_tests,
            "total_tests": total_tests,
            "detailed_results": self.results
        }

if __name__ == "__main__":
    tester = MicroservicesSimulationTester()
    results = tester.run_comprehensive_test()
    exit(0 if results["overall_success"] else 1)